# streamlit_app.py
# -*- coding: utf-8 -*-
import os
import textwrap
import streamlit as st
import pandas as pd
import numpy as np
import altair as alt

# ------------------------------
# ê¸°ë³¸ ì„¤ì •
# ------------------------------
st.set_page_config(page_title="AI Ã— Dev: ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ (KR v2)", layout="wide")

# Altair í…Œë§ˆ (Altair 5.5+)
try:
    alt.theme.enable("quartz")  # 'default' ë˜ëŠ” 'quartz' ì‚¬ìš© ê°€ëŠ¥
except Exception:
    pass

# ------------------------------
# ìœ í‹¸ í•¨ìˆ˜
# ------------------------------
@st.cache_data(show_spinner=False, ttl=0)  # ê°œë°œ ì¤‘ì—” TTL=0; ë°°í¬ ì‹œ ì œê±°/ì¡°ì •
def load_csv(path_or_file, **kwargs) -> pd.DataFrame:
    return pd.read_csv(path_or_file, low_memory=False, **kwargs)

EXCLUDE_TOKENS = {"", "-", "nan", "None", "null"}

def normalize_multiselect_series(series: pd.Series) -> pd.Series:
    s = series.fillna("").astype(str)
    s = s.str.replace(";", ",", regex=False)
    return s

def explode_multiselect(df: pd.DataFrame, col: str) -> pd.DataFrame:
    """ë‹¤ì¤‘ì‘ë‹µì„ í–‰ìœ¼ë¡œ í­ë°œ. ë¹ˆê°’/'-' ì œê±°."""
    if col not in df.columns:
        return pd.DataFrame(columns=[col])
    s = normalize_multiselect_series(df[col]).str.split(",")

    def clean(lst):
        out = []
        for x in (lst or []):
            x = str(x).strip()
            if x in EXCLUDE_TOKENS:
                continue
            out.append(x)
        return out

    s = s.apply(clean)
    exploded = df.assign(**{col: s}).explode(col)
    if col in exploded.columns:
        exploded[col] = exploded[col].astype(str).str.strip()
        exploded = exploded[~exploded[col].isin(EXCLUDE_TOKENS)]
    return exploded

def value_counts_pct(series: pd.Series) -> pd.DataFrame:
    """ë¹ˆë„/ë¹„ìœ¨ í‘œ ìƒì„±. ë¹„ì–´ë„ ì»¬ëŸ¼ ìŠ¤ì¼ˆë ˆí†¤ ìœ ì§€."""
    s = series.replace({np.nan: None}).dropna().astype(str)
    s = s[~s.isin(list(EXCLUDE_TOKENS))]
    if s.empty:
        return pd.DataFrame(columns=["count", "percent"])
    vc = s.value_counts()
    pct = 100 * vc / vc.sum()
    return pd.DataFrame({"count": vc.astype(int), "percent": pct.round(2)})

def prep_for_chart(vc_df: pd.DataFrame, label_name: str) -> pd.DataFrame:
    """Altair ì°¨íŠ¸ìš© ì¸ë±ìŠ¤â†’ì»¬ëŸ¼ ì „ê°œ + dtype ê°•ì œ. ë¹„ì–´ë„ ì»¬ëŸ¼ ë³´ì¥."""
    if vc_df is None or len(vc_df) == 0:
        return pd.DataFrame(columns=[label_name, "count", "percent"])
    df = vc_df.reset_index()
    df = df.rename(columns={df.columns[0]: label_name})
    df[label_name] = df[label_name].astype(str)
    if "count" in df.columns:
        df["count"] = pd.to_numeric(df["count"], errors="coerce")
    if "percent" in df.columns:
        df["percent"] = pd.to_numeric(df["percent"], errors="coerce")
    return df

def wrap_label(s: str, width: int = 16) -> str:
    parts = textwrap.wrap(str(s), width=width)
    return "\n".join(parts) if parts else s

def safe_sort(df: pd.DataFrame, by: str, ascending=True) -> pd.DataFrame:
    if df is None or df.empty or by not in df.columns:
        return df
    return df.sort_values(by, ascending=ascending)

def require_file(path_or_file, label: str):
    """ì—…ë¡œë“œ íŒŒì¼ì€ í†µê³¼, ë¬¸ìì—´ ê²½ë¡œë©´ ì¡´ì¬ í™•ì¸ í›„ ì—†ìœ¼ë©´ stop."""
    if hasattr(path_or_file, "read"):
        return
    if isinstance(path_or_file, str) and not os.path.exists(path_or_file):
        st.error(f"{label} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path_or_file}\nì‚¬ì´ë“œë°”ì—ì„œ CSV ì—…ë¡œë“œ ë˜ëŠ” ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

# ------------------------------
# í•œê¸€ ë§¤í•‘
# ------------------------------
TOOLS_MAP = {
    "Chatbots": "ì±—ë´‡",
    "Predictive Analytics": "ì˜ˆì¸¡ ë¶„ì„",
    "Machine Learning Algorithms": "ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜",
    "Natural Language Processing": "ìì—°ì–´ ì²˜ë¦¬",
    "Natural Language Processing (NLP)": "ìì—°ì–´ ì²˜ë¦¬",
    "NLP": "ìì—°ì–´ ì²˜ë¦¬",
    "ML Algorithms": "ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜",
    "GenAI tools": "ìƒì„±í˜• AI ë„êµ¬",
    "Computer Vision": "ì»´í“¨í„° ë¹„ì „",
    "Recommendation Systems": "ì¶”ì²œ ì‹œìŠ¤í…œ",
    "RPA": "RPA(ë¡œë´‡ í”„ë¡œì„¸ìŠ¤ ìë™í™”)",
}

BENEFITS_MAP = {
    "Increased productivity": "ìƒì‚°ì„± ì¦ê°€",
    "Faster prototyping": "ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘",
    "Improved documentation": "ë¬¸ì„œí™” í–¥ìƒ",
    "Better decision-making": "ì˜ì‚¬ê²°ì • í’ˆì§ˆ í–¥ìƒ",
    "Automation of repetitive tasks": "ë°˜ë³µ ì‘ì—… ìë™í™”",
    "Enhanced code quality": "ì½”ë“œ í’ˆì§ˆ í–¥ìƒ",
}

CHALLENGE_MAP = {
    "Ethical considerations": "ìœ¤ë¦¬ì  ê³ ë ¤",
    "Cost implications": "ë¹„ìš© ë¶€ë‹´",
    "Lack of expertise": "ì „ë¬¸ì„± ë¶€ì¡±",
    "Lack of expertise in AI technologies": "ì „ë¬¸ì„± ë¶€ì¡±",
    "Resistance from team": "íŒ€ ë‚´ ì €í•­",
    "Resistance from team members": "íŒ€ ë‚´ ì €í•­",
    "Integration complexity": "ì‹œìŠ¤í…œ í†µí•© ë³µì¡ì„±",
    "Integration complexities": "ì‹œìŠ¤í…œ í†µí•© ë³µì¡ì„±",
    "Data privacy concerns": "ë°ì´í„° í”„ë¼ì´ë²„ì‹œ ìš°ë ¤",
    "Quality/accuracy concerns": "í’ˆì§ˆÂ·ì •í™•ë„ ìš°ë ¤",
    "Compliance/regulatory issues": "ê·œì œÂ·ì»´í”Œë¼ì´ì–¸ìŠ¤ ì´ìŠˆ",
}

# Stack Overflow DevType (ëŒ€í‘œ í•­ëª© ìœ„ì£¼. ì—†ìœ¼ë©´ ì›ë¬¸ ìœ ì§€)
DEVTYPE_MAP = {
    "Developer, back-end": "ë°±ì—”ë“œ ê°œë°œì",
    "Developer, front-end": "í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì",
    "Developer, full-stack": "í’€ìŠ¤íƒ ê°œë°œì",
    "Developer, mobile": "ëª¨ë°”ì¼ ê°œë°œì",
    "Developer, desktop or enterprise applications": "ë°ìŠ¤í¬í†±/ì—”í„°í”„ë¼ì´ì¦ˆ ê°œë°œì",
    "Developer, embedded applications or devices": "ì„ë² ë””ë“œ ê°œë°œì",
    "Developer, game or graphics": "ê²Œì„/ê·¸ë˜í”½ìŠ¤ ê°œë°œì",
    "Data scientist or machine learning specialist": "ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸/ML ì „ë¬¸ê°€",
    "Data or business analyst": "ë°ì´í„°/ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ê°€",
    "Database administrator": "DB ê´€ë¦¬ì",
    "DevOps specialist": "ë°ë¸Œì˜µìŠ¤ ì „ë¬¸ê°€",
    "Security professional": "ë³´ì•ˆ ì „ë¬¸ê°€",
    "Engineering manager": "ì—”ì§€ë‹ˆì–´ë§ ë§¤ë‹ˆì €",
    "Academic researcher": "í•™ìˆ  ì—°êµ¬ì",
    "Scientist": "ê³¼í•™ì",
    "Student": "í•™ìƒ",
    "System administrator": "ì‹œìŠ¤í…œ ê´€ë¦¬ì",
    "Cloud infrastructure engineer": "í´ë¼ìš°ë“œ ì¸í”„ë¼ ì—”ì§€ë‹ˆì–´",
    "Site reliability engineer": "SRE",
}

# ------------------------------
# ì‚¬ì´ë“œë°” / ê²½ë¡œ
# ------------------------------
st.sidebar.header("ë°ì´í„° ì†ŒìŠ¤ ì„¤ì •")

# ì•± íŒŒì¼ê³¼ ê°™ì€ í´ë” ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ
DEFAULT_SO = "data/survey_results_public.csv"
DEFAULT_AI = "data/Survey on Integrating Artificial Intelligence Tools within Agile Frameworks for Enhanced Software Development (Responses) - Sheet1.csv"

dataset = st.sidebar.radio("ë¶„ì„ ëŒ€ìƒ", ["AI in Agile ì„¤ë¬¸", "Stack Overflow 2023"], index=0, key="dataset_radio")

# ------------------------------
# AI in Agile ì„¤ë¬¸
# ------------------------------
if dataset == "AI in Agile ì„¤ë¬¸":
    st.title("AI in Agile ì„¤ë¬¸ ë¶„ì„")
    st.caption("AI ë„êµ¬ ì‚¬ìš© ê²½í—˜/ìœ í˜•, ê¸°ëŒ€íš¨ê³¼Â·ìš°ë ¤, ë„ì… ì˜í–¥, êµì°¨í‘œ í¬í•¨")

    # ì—…ë¡œë“œ/ê²½ë¡œ
    up = st.sidebar.file_uploader("AI ì„¤ë¬¸ CSV ì—…ë¡œë“œ", type=["csv"], key="ai_csv")
    path = up if up is not None else DEFAULT_AI
    require_file(path, "AI ì„¤ë¬¸")
    ai = load_csv(path)

    # ì»¬ëŸ¼ëª… ì¶•ì•½
    mapper = {
        'Current Role: ': 'Role',
        'Familiarity with Agile Frameworks:': 'AgileFamiliarity',
        'Familiarity with Artificial Intelligence Tools(Like ChatGPT ):': 'AIFamiliarity',
        'Have you used artificial intelligence tools in software development projects before?': 'AIUsedBefore',
        'If yes, please specify the types of artificial intelligence tools you have used (check all that apply):': 'AIToolsUsed',
        'How do you perceive the potential benefits of integrating AI...e frameworks for software development? (Check all that apply):': 'Benefits',
        'What challenges do you foresee in integrating AI tools within agile frameworks? (Check all that apply):': 'Challenges',
        'On a scale of 1 to 5, how willing would you be to adopt AI tools within your agile development processes?': 'Willingness'
    }
    ai = ai.rename(columns={k: v for k, v in mapper.items() if k in ai.columns})

    # ê²°ì¸¡ì¹˜ ì •ë¦¬
    for col in ["Role","AgileFamiliarity","AIFamiliarity","AIUsedBefore","AIToolsUsed","Benefits","Challenges"]:
        if col in ai.columns:
            ai[col] = ai[col].fillna("")

    if "Willingness" in ai.columns:
        ai["Willingness"] = pd.to_numeric(ai["Willingness"], errors="coerce")

    # ë¯¸ë¦¬ë³´ê¸°
    with st.expander("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° / ìŠ¤í‚¤ë§ˆ"):
        c1, c2 = st.columns([2,1])
        with c1:
            st.dataframe(ai.head(20))
        with c2:
            st.write({"rows": int(ai.shape[0]), "cols": int(ai.shape[1])})
            st.write("ì»¬ëŸ¼:", list(ai.columns))

    # í•„í„°
    roles = sorted([r for r in ai.get("Role", pd.Series(dtype=str)).dropna().unique() if r]) if "Role" in ai.columns else []
    fams  = sorted([r for r in ai.get("AIFamiliarity", pd.Series(dtype=str)).dropna().unique() if r]) if "AIFamiliarity" in ai.columns else []
    sel_roles = st.sidebar.multiselect("ì—­í• (Role)", roles, default=[], key="roles_ms")
    sel_fams  = st.sidebar.multiselect("AI ë„êµ¬ ì¹œìˆ™ë„", fams, default=[], key="fams_ms")

    df_f = ai.copy()
    if sel_roles and "Role" in df_f.columns:
        df_f = df_f[df_f["Role"].isin(sel_roles)]
    if sel_fams and "AIFamiliarity" in df_f.columns:
        df_f = df_f[df_f["AIFamiliarity"].isin(sel_fams)]

    # KPI
    k2,k3,k4 = st.columns(3)
    with k2:
        if "AIUsedBefore" in df_f.columns and len(df_f) > 0:
            used_rate = (df_f["AIUsedBefore"].astype(str).str.lower().isin(["yes","y","true","1"]).mean()*100)
            st.metric("AI ì‚¬ìš© ê²½í—˜ë¥ (%)", f"{used_rate:.1f}")
        else:
            st.metric("AI ì‚¬ìš© ê²½í—˜ë¥ (%)", "N/A")
    with k3:
        if "Willingness" in df_f.columns and df_f["Willingness"].notna().any():
            st.metric("í‰ê·  ë„ì… ì˜í–¥(1~5)", f"{df_f['Willingness'].mean():.2f}")
        else:
            st.metric("í‰ê·  ë„ì… ì˜í–¥(1~5)", "N/A")
    with k4:
        if "Willingness" in df_f.columns and df_f["Willingness"].notna().any():
            st.metric("ì˜í–¥ ì¤‘ì•™ê°’", f"{df_f['Willingness'].median():.2f}")
        else:
            st.metric("ì˜í–¥ ì¤‘ì•™ê°’", "N/A")

    # 1) AI ì‚¬ìš© ê²½í—˜
    st.subheader("1) AI ì‚¬ìš© ê²½í—˜ ë¶„í¬")
    if "AIUsedBefore" in df_f.columns:
        vc = value_counts_pct(df_f["AIUsedBefore"])
        d = prep_for_chart(vc, "AIUsedBefore")
        if not d.empty:
            base = alt.Chart(d).properties(height=200)
            bars = base.mark_bar().encode(
                y=alt.Y("AIUsedBefore:N", sort="-x", title="ê²½í—˜ ì—¬ë¶€"),
                x=alt.X("count:Q", title="ì‘ë‹µ ìˆ˜"),
                tooltip=["AIUsedBefore","count","percent"]
            )
            texts = base.mark_text(align="left", baseline="middle", dx=4).encode(
                y=alt.Y("AIUsedBefore:N", sort="-x"),
                x=alt.X("count:Q"),
                text="count:Q"
            )
            st.altair_chart(bars + texts, use_container_width=True)
        st.dataframe(d.rename(columns={"AIUsedBefore":"ê²½í—˜ ì—¬ë¶€","count":"ì‘ë‹µ ìˆ˜","percent":"ë¹„ìœ¨(%)"}))

    # 2) ì‚¬ìš©í•œ AI ë„êµ¬ ìœ í˜• (í•œê¸€í™” + '-' ì œê±°)
    st.subheader("2) ì‚¬ìš©í•œ AI ë„êµ¬ ìœ í˜•")
    if "AIToolsUsed" in df_f.columns:
        tools = explode_multiselect(df_f, "AIToolsUsed")
        if len(tools) > 0:
            t = tools["AIToolsUsed"].map(TOOLS_MAP).fillna(tools["AIToolsUsed"])
            vc2 = value_counts_pct(t)
            d2 = prep_for_chart(vc2, "Tool_ko")
            d2["Tool_ko_wrapped"] = d2["Tool_ko"].apply(lambda s: wrap_label(s, 16))

            if not d2.empty:
                base2 = alt.Chart(d2).properties(height=max(220, 28 * len(d2)))
                bars2 = base2.mark_bar().encode(
                    y=alt.Y("Tool_ko_wrapped:N", sort="-x", title="ë„êµ¬"),
                    x=alt.X("count:Q", title="ì‘ë‹µ ìˆ˜"),
                    tooltip=["Tool_ko","count","percent"]
                )
                texts2 = base2.mark_text(align="left", baseline="middle", dx=4).encode(
                    y=alt.Y("Tool_ko_wrapped:N", sort="-x"),
                    x=alt.X("count:Q"),
                    text="count:Q"
                )
                st.altair_chart(bars2 + texts2, use_container_width=True)

            tbl2 = d2[["Tool_ko","count","percent"]].rename(
                columns={"Tool_ko":"ë„êµ¬","count":"ì‘ë‹µ ìˆ˜","percent":"ë¹„ìœ¨(%)"}
            )
            st.dataframe(safe_sort(tbl2, "ì‘ë‹µ ìˆ˜", ascending=False))

    # 3) ê¸°ëŒ€ íš¨ê³¼ (í•œê¸€í™”)
    st.subheader("3) ê¸°ëŒ€ íš¨ê³¼(Benefits)")
    if "Benefits" in df_f.columns:
        ben = explode_multiselect(df_f, "Benefits")
        if len(ben) > 0:
            ben["Benefits"] = ben["Benefits"].astype(str).str.strip()
            ben = ben[~ben["Benefits"].isin(EXCLUDE_TOKENS)]
            ben_ko = ben["Benefits"].map(BENEFITS_MAP).fillna(ben["Benefits"])

            vc3 = value_counts_pct(ben_ko)
            d3 = prep_for_chart(vc3, "Benefit_ko")
            d3["Benefit_ko_wrapped"] = d3["Benefit_ko"].apply(lambda s: wrap_label(s, 16))

            if not d3.empty:
                base3 = alt.Chart(d3).properties(height=max(220, 28 * len(d3)))
                bars3 = base3.mark_bar().encode(
                    y=alt.Y("Benefit_ko_wrapped:N", sort="-x", title="ê¸°ëŒ€ íš¨ê³¼"),
                    x=alt.X("count:Q", title="ì‘ë‹µ ìˆ˜"),
                    tooltip=["Benefit_ko","count","percent"]
                )
                texts3 = base3.mark_text(align="left", baseline="middle", dx=4).encode(
                    y=alt.Y("Benefit_ko_wrapped:N", sort="-x"),
                    x=alt.X("count:Q"),
                    text="count:Q"
                )
                st.altair_chart(bars3 + texts3, use_container_width=True)

            st.dataframe(
                d3[["Benefit_ko","count","percent"]].rename(
                    columns={"Benefit_ko":"ê¸°ëŒ€ íš¨ê³¼(í•œê¸€)","count":"ì‘ë‹µ ìˆ˜","percent":"ë¹„ìœ¨(%)"}
                )
            )

    # 4) ìš°ë ¤/ì¥ì• ìš”ì¸ (í•œê¸€í™” + ì¤„ë°”ê¿ˆ + '-' ì œê±°)
    st.subheader("4) ìš°ë ¤/ì¥ì• ìš”ì¸(Challenges)")
    if "Challenges" in df_f.columns:
        ch = explode_multiselect(df_f, "Challenges")
        if len(ch) > 0:
            ch["Challenges"] = ch["Challenges"].astype(str).str.strip()
            ch = ch[~ch["Challenges"].isin(EXCLUDE_TOKENS)]
            ch_ko = ch["Challenges"].map(CHALLENGE_MAP).fillna(ch["Challenges"])

            vc4 = value_counts_pct(ch_ko)
            d4 = prep_for_chart(vc4, "Challenge_ko")
            d4["Challenge_ko_wrapped"] = d4["Challenge_ko"].apply(lambda s: wrap_label(s, 16))

            if not d4.empty:
                base4 = alt.Chart(d4).properties(height=max(220, 28 * len(d4)))
                bars4 = base4.mark_bar().encode(
                    y=alt.Y("Challenge_ko_wrapped:N", sort="-x", title="ì¥ì• ìš”ì¸"),
                    x=alt.X("count:Q", title="ì‘ë‹µ ìˆ˜"),
                    tooltip=["Challenge_ko","count","percent"]
                )
                texts4 = base4.mark_text(align="left", baseline="middle", dx=4).encode(
                    y=alt.Y("Challenge_ko_wrapped:N", sort="-x"),
                    x=alt.X("count:Q"),
                    text="count:Q"
                )
                st.altair_chart(bars4 + texts4, use_container_width=True)

            tbl4 = d4[["Challenge_ko","count","percent"]].rename(
                columns={"Challenge_ko":"ì¥ì• ìš”ì¸(í•œê¸€)","count":"ì‘ë‹µ ìˆ˜","percent":"ë¹„ìœ¨(%)"}
            )
            st.dataframe(safe_sort(tbl4, "ì‘ë‹µ ìˆ˜", ascending=False))

    # 5) ë„ì… ì˜í–¥ ë¶„í¬
    st.subheader("5) ë„ì… ì˜í–¥ ë¶„í¬ (1=ë‚®ìŒ, 5=ë§¤ìš° ë†’ìŒ)")
    if "Willingness" in df_f.columns and df_f["Willingness"].notna().any():
        vc5 = value_counts_pct(df_f["Willingness"].dropna())
        d5 = prep_for_chart(vc5, "Score")

        if not d5.empty and "Score" in d5.columns:
            chart5 = alt.Chart(d5).mark_bar().encode(
                x=alt.X("Score:O", title="ë„ì… ì˜í–¥ ì ìˆ˜"),
                y=alt.Y("count:Q", title="ì‘ë‹µ ìˆ˜"),
                tooltip=["Score","count","percent"]
            )
            st.altair_chart(chart5, use_container_width=True)

            tbl5 = d5.rename(columns={"Score":"ì ìˆ˜","count":"ì‘ë‹µ ìˆ˜","percent":"ë¹„ìœ¨(%)"})
            st.dataframe(safe_sort(tbl5, "ì ìˆ˜"))
        else:
            st.info("ìœ íš¨í•œ ë„ì… ì˜í–¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ë„ì… ì˜í–¥(Willingness) ì»¬ëŸ¼ì´ ì—†ê±°ë‚˜ ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")

    # ë‹¤ìš´ë¡œë“œ
    st.download_button(
        "ğŸ”½ í˜„ì¬ í•„í„° ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
        data=df_f.to_csv(index=False).encode("utf-8-sig"),
        file_name="ai_agile_filtered.csv",
        mime="text/csv"
    )

# ------------------------------
# Stack Overflow 2023
# ------------------------------
else:
    st.title("Stack Overflow 2023 íƒìƒ‰")
    st.caption("ì§ë¬´/ì–¸ì–´/ê²½ë ¥ ë¶„í¬ + êµ­ê°€/ì¡°ì§ê·œëª¨ í•„í„°")

    up = st.sidebar.file_uploader("SO 2023 CSV ì—…ë¡œë“œ", type=["csv"], key="so_csv")
    path = up if up is not None else DEFAULT_SO
    require_file(path, "SO 2023 ë°ì´í„°")
    so = load_csv(path)

    with st.expander("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° / ìŠ¤í‚¤ë§ˆ"):
        c1, c2 = st.columns([2,1])
        with c1:
            st.dataframe(so.head(20))
        with c2:
            st.write({"rows": int(so.shape[0]), "cols": int(so.shape[1])})
            st.write("ì»¬ëŸ¼:", list(so.columns))

    countries = sorted([c for c in so.get("Country", pd.Series(dtype=str)).dropna().unique() if c]) if "Country" in so.columns else []
    sel_countries = st.sidebar.multiselect("êµ­ê°€", countries, default=[], key="country_ms")
    orgs = sorted([o for o in so.get("OrgSize", pd.Series(dtype=str)).dropna().unique() if o]) if "OrgSize" in so.columns else []
    sel_orgs = st.sidebar.multiselect("ì¡°ì§ ê·œëª¨", orgs, default=[], key="org_ms")

    so_f = so.copy()
    if sel_countries and "Country" in so_f.columns:
        so_f = so_f[so_f["Country"].isin(sel_countries)]
    if sel_orgs and "OrgSize" in so_f.columns:
        so_f = so_f[so_f["OrgSize"].isin(sel_orgs)]

    # 1) DevType (í•œê¸€í™” + ê°€ë¡œ ë§‰ëŒ€)
    st.subheader("1) ì§ë¬´(DevType) ë¶„í¬")
    if "DevType" in so_f.columns:
        dev = so_f["DevType"].fillna("").str.split(";").explode().str.strip()
        dev = dev[~dev.isin(EXCLUDE_TOKENS)]
        if len(dev) > 0:
            dev_ko = dev.map(DEVTYPE_MAP).fillna(dev)
            vc = value_counts_pct(dev_ko)
            d = prep_for_chart(vc, "DevType_ko")
            d["DevType_ko_wrapped"] = d["DevType_ko"].apply(lambda s: wrap_label(s, 16))

            if not d.empty:
                base = alt.Chart(d).properties(height=max(220, 28 * len(d)))
                bars = base.mark_bar().encode(
                    y=alt.Y("DevType_ko_wrapped:N", sort="-x", title="ì§ë¬´"),
                    x=alt.X("count:Q", title="ì‘ë‹µ ìˆ˜"),
                    tooltip=["DevType_ko","count","percent"]
                )
                texts = base.mark_text(align="left", baseline="middle", dx=4).encode(
                    y=alt.Y("DevType_ko_wrapped:N", sort="-x"),
                    x=alt.X("count:Q"),
                    text="count:Q"
                )
                st.altair_chart(bars + texts, use_container_width=True)

            tbl_dev = d.rename(columns={"DevType_ko":"ì§ë¬´","count":"ì‘ë‹µ ìˆ˜","percent":"ë¹„ìœ¨(%)"})
            st.dataframe(safe_sort(tbl_dev, "ì‘ë‹µ ìˆ˜", ascending=False))

    # 2) LanguageHaveWorkedWith (ê°€ë¡œ ë§‰ëŒ€)
    st.subheader("2) ì‚¬ìš© ì–¸ì–´(LanguageHaveWorkedWith)")
    if "LanguageHaveWorkedWith" in so_f.columns:
        lang = so_f["LanguageHaveWorkedWith"].fillna("").str.split(";").explode().str.strip()
        lang = lang[~lang.isin(EXCLUDE_TOKENS)]
        if len(lang) > 0:
            vc2 = value_counts_pct(lang)
            d2 = prep_for_chart(vc2, "Language")
            d2["Language_wrapped"] = d2["Language"].apply(lambda s: wrap_label(s, 16))

            if not d2.empty:
                base2 = alt.Chart(d2).properties(height=max(220, 28 * len(d2)))
                bars2 = base2.mark_bar().encode(
                    y=alt.Y("Language_wrapped:N", sort="-x", title="ì–¸ì–´"),
                    x=alt.X("count:Q", title="ì‘ë‹µ ìˆ˜"),
                    tooltip=["Language","count","percent"]
                )
                texts2 = base2.mark_text(align="left", baseline="middle", dx=4).encode(
                    y=alt.Y("Language_wrapped:N", sort="-x"),
                    x=alt.X("count:Q"),
                    text="count:Q"
                )
                st.altair_chart(bars2 + texts2, use_container_width=True)

            st.dataframe(d2.rename(columns={"Language":"ì–¸ì–´","count":"ì‘ë‹µ ìˆ˜","percent":"ë¹„ìœ¨(%)"}).pipe(lambda x: safe_sort(x, "ì‘ë‹µ ìˆ˜", ascending=False)))

    # 3) YearsCodePro
    st.subheader("3) ê²½ë ¥(YearsCodePro) ë¶„í¬")
    if "YearsCodePro" in so_f.columns:
        y = so_f["YearsCodePro"].replace({"Less than 1 year": "0", "More than 50 years": "51"})
        y_num = pd.to_numeric(y, errors="coerce").dropna()
        vc3 = value_counts_pct(y_num)
        d3 = prep_for_chart(vc3, "Years")
        if not d3.empty:
            chart3 = alt.Chart(d3).mark_bar().encode(
                x=alt.X("Years:Q", title="ê²½ë ¥(ë…„)"),
                y=alt.Y("count:Q", title="ì‘ë‹µ ìˆ˜"),
                tooltip=["Years","count","percent"]
            )
            st.altair_chart(chart3, use_container_width=True)
        st.dataframe(d3.rename(columns={"Years":"ê²½ë ¥(ë…„)","count":"ì‘ë‹µ ìˆ˜","percent":"ë¹„ìœ¨(%)"}).pipe(lambda x: safe_sort(x, "Years")))

    # ë‹¤ìš´ë¡œë“œ
    st.download_button(
        "ğŸ”½ í˜„ì¬ í•„í„° ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
        data=so_f.to_csv(index=False).encode("utf-8-sig"),
        file_name="so2023_filtered.csv",
        mime="text/csv"
    )

# ------------------------------
# ë„ì›€ë§
# ------------------------------
st.markdown("---")
with st.expander("ì‚¬ìš© ë°©ë²• / íŒ"):
    st.markdown(
        """
        - ëª¨ë“  ë¶„í¬ëŠ” ê°€ë…ì„±ì„ ìœ„í•´ **ê°€ë¡œ ë§‰ëŒ€**ì™€ **ê°’ ë¼ë²¨**ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.  
        - ë‹¤ì¤‘ì‘ë‹µ í•„ë“œì—ì„œ `-`/ë¹ˆê°’/NaNì€ ìë™ ì œê±°ë©ë‹ˆë‹¤.  
        - ë„êµ¬/ì¥ì• ìš”ì¸/DevTypeì€ í•œêµ­ì–´ë¡œ ë§¤í•‘(ë¯¸ì •ì˜ í•­ëª©ì€ ì›ë¬¸ ìœ ì§€).  
        - ê°œë°œ ì¤‘ì—ëŠ” ìºì‹œ TTL=0ìœ¼ë¡œ í•­ìƒ ì¬ê³„ì‚°í•©ë‹ˆë‹¤(ë°°í¬ ì‹œ ì¡°ì • ê¶Œì¥).
        """
    )
