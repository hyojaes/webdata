# streamlit_app.py
# -*- coding: utf-8 -*-
import os
import textwrap
import streamlit as st
import pandas as pd
import numpy as np
import altair as alt

# ------------------------------
# ê¸°ë³¸ ì„¤ì •
# ------------------------------
st.set_page_config(
    page_title="AI Ã— Dev: ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ (KR v2)",
    layout="wide"
)

# Altair í…Œë§ˆ (Altair 5.5+)
try:
    alt.theme.enable("quartz")  # 'default' ë˜ëŠ” 'quartz' ì‚¬ìš© ê°€ëŠ¥
except Exception:
    pass

# ------------------------------
# ìœ í‹¸ í•¨ìˆ˜
# ------------------------------
@st.cache_data(show_spinner=False, ttl=0)  # ê°œë°œ ì¤‘ì—” TTL=0; ë°°í¬ ì‹œ ì œê±°/ì¡°ì •
def load_csv(path_or_file, **kwargs) -> pd.DataFrame:
    return pd.read_csv(path_or_file, low_memory=False, **kwargs)

EXCLUDE_TOKENS = {"", "-", "nan", "None", "null"}

def normalize_multiselect_series(series: pd.Series) -> pd.Series:
    s = series.fillna("").astype(str)
    s = s.str.replace(";", ",", regex=False)
    return s

def explode_multiselect(df: pd.DataFrame, col: str) -> pd.DataFrame:
    """ë‹¤ì¤‘ì‘ë‹µì„ í–‰ìœ¼ë¡œ í­ë°œ. ë¹ˆê°’/'-' ì œê±°."""
    if col not in df.columns:
        return pd.DataFrame(columns=[col])
    s = normalize_multiselect_series(df[col]).str.split(",")

    def clean(lst):
        out = []
        for x in (lst or []):
            x = str(x).strip()
            if x in EXCLUDE_TOKENS:
                continue
            out.append(x)
        return out

    s = s.apply(clean)
    exploded = df.assign(**{col: s}).explode(col)
    if col in exploded.columns:
        exploded[col] = exploded[col].astype(str).str.strip()
        exploded = exploded[~exploded[col].isin(EXCLUDE_TOKENS)]
    return exploded

def value_counts_pct(series: pd.Series) -> pd.DataFrame:
    """ë¹ˆë„/ë¹„ìœ¨ í‘œ ìƒì„±. ë¹„ì–´ë„ ì»¬ëŸ¼ ìŠ¤ì¼ˆë ˆí†¤ ìœ ì§€."""
    s = series.replace({np.nan: None}).dropna().astype(str)
    s = s[~s.isin(list(EXCLUDE_TOKENS))]
    if s.empty:
        return pd.DataFrame(columns=["count", "percent"])
    vc = s.value_counts()
    pct = 100 * vc / vc.sum()
    return pd.DataFrame({"count": vc.astype(int), "percent": pct.round(2)})

def prep_for_chart(vc_df: pd.DataFrame, label_name: str) -> pd.DataFrame:
    """Altair ì°¨íŠ¸ìš© ì¸ë±ìŠ¤â†’ì»¬ëŸ¼ ì „ê°œ + dtype ê°•ì œ. ë¹„ì–´ë„ ì»¬ëŸ¼ ë³´ì¥."""
    if vc_df is None or len(vc_df) == 0:
        return pd.DataFrame(columns=[label_name, "count", "percent"])
    df = vc_df.reset_index()
    df = df.rename(columns={df.columns[0]: label_name})
    df[label_name] = df[label_name].astype(str)
    if "count" in df.columns:
        df["count"] = pd.to_numeric(df["count"], errors="coerce")
    if "percent" in df.columns:
        df["percent"] = pd.to_numeric(df["percent"], errors="coerce")
    return df

def wrap_label(s: str, width: int = 16) -> str:
    parts = textwrap.wrap(str(s), width=width)
    return "\n".join(parts) if parts else s

def safe_sort(df: pd.DataFrame, by: str, ascending=True) -> pd.DataFrame:
    if df is None or df.empty or by not in df.columns:
        return df
    return df.sort_values(by, ascending=ascending)

def require_file(path_or_file, label: str):
    """ì—…ë¡œë“œ íŒŒì¼ì€ í†µê³¼, ë¬¸ìì—´ ê²½ë¡œë©´ ì¡´ì¬ í™•ì¸ í›„ ì—†ìœ¼ë©´ stop."""
    if hasattr(path_or_file, "read"):
        return
    if isinstance(path_or_file, str) and not os.path.exists(path_or_file):
        st.error(f"{label} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path_or_file}\nì‚¬ì´ë“œë°”ì—ì„œ CSV ì—…ë¡œë“œ ë˜ëŠ” ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

# ------------------------------
# í•œê¸€ ë§¤í•‘
# ------------------------------
TOOLS_MAP = {
    "Chatbots": "ì±—ë´‡",
    "Predictive Analytics": "ì˜ˆì¸¡ ë¶„ì„",
    "Machine Learning Algorithms": "ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜",
    "Natural Language Processing": "ìì—°ì–´ ì²˜ë¦¬",
    "Natural Language Processing (NLP)": "ìì—°ì–´ ì²˜ë¦¬",
    "NLP": "ìì—°ì–´ ì²˜ë¦¬",
    "ML Algorithms": "ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜",
    "GenAI tools": "ìƒì„±í˜• AI ë„êµ¬",
    "Computer Vision": "ì»´í“¨í„° ë¹„ì „",
    "Recommendation Systems": "ì¶”ì²œ ì‹œìŠ¤í…œ",
    "RPA": "RPA(ë¡œë´‡ í”„ë¡œì„¸ìŠ¤ ìë™í™”)",
}

BENEFITS_MAP = {
    "Increased productivity": "ìƒì‚°ì„± ì¦ê°€",
    "Faster prototyping": "ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘",
    "Improved documentation": "ë¬¸ì„œí™” í–¥ìƒ",
    "Better decision-making": "ì˜ì‚¬ê²°ì • í’ˆì§ˆ í–¥ìƒ",
    "Automation of repetitive tasks": "ë°˜ë³µ ì‘ì—… ìë™í™”",
    "Enhanced code quality": "ì½”ë“œ í’ˆì§ˆ í–¥ìƒ",
}

CHALLENGE_MAP = {
    "Ethical considerations": "ìœ¤ë¦¬ì  ê³ ë ¤",
    "Cost implications": "ë¹„ìš© ë¶€ë‹´",
    "Lack of expertise": "ì „ë¬¸ì„± ë¶€ì¡±",
    "Lack of expertise in AI technologies": "ì „ë¬¸ì„± ë¶€ì¡±",
    "Resistance from team": "íŒ€ ë‚´ ì €í•­",
    "Resistance from team members": "íŒ€ ë‚´ ì €í•­",
    "Integration complexity": "ì‹œìŠ¤í…œ í†µí•© ë³µì¡ì„±",
    "Integration complexities": "ì‹œìŠ¤í…œ í†µí•© ë³µì¡ì„±",
    "Data privacy concerns": "ë°ì´í„° í”„ë¼ì´ë²„ì‹œ ìš°ë ¤",
    "Quality/accuracy concerns": "í’ˆì§ˆÂ·ì •í™•ë„ ìš°ë ¤",
    "Compliance/regulatory issues": "ê·œì œÂ·ì»´í”Œë¼ì´ì–¸ìŠ¤ ì´ìŠˆ",
}

DEVTYPE_MAP = {
    "Developer, back-end": "ë°±ì—”ë“œ ê°œë°œì",
    "Developer, front-end": "í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì",
    "Developer, full-stack": "í’€ìŠ¤íƒ ê°œë°œì",
    "Developer, mobile": "ëª¨ë°”ì¼ ê°œë°œì",
    "Developer, desktop or enterprise applications": "ë°ìŠ¤í¬í†±/ì—”í„°í”„ë¼ì´ì¦ˆ ê°œë°œì",
    "Developer, embedded applications or devices": "ì„ë² ë””ë“œ ê°œë°œì",
    "Developer, game or graphics": "ê²Œì„/ê·¸ë˜í”½ìŠ¤ ê°œë°œì",
    "Data scientist or machine learning specialist": "ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸/ML ì „ë¬¸ê°€",
    "Data or business analyst": "ë°ì´í„°/ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ê°€",
    "Database administrator": "DB ê´€ë¦¬ì",
    "DevOps specialist": "ë°ë¸Œì˜µìŠ¤ ì „ë¬¸ê°€",
    "Security professional": "ë³´ì•ˆ ì „ë¬¸ê°€",
    "Engineering manager": "ì—”ì§€ë‹ˆì–´ë§ ë§¤ë‹ˆì €",
    "Academic researcher": "í•™ìˆ  ì—°êµ¬ì",
    "Scientist": "ê³¼í•™ì",
    "Student": "í•™ìƒ",
    "System administrator": "ì‹œìŠ¤í…œ ê´€ë¦¬ì",
    "Cloud infrastructure engineer": "í´ë¼ìš°ë“œ ì¸í”„ë¼ ì—”ì§€ë‹ˆì–´",
    "Site reliability engineer": "SRE",
}

# ------------------------------
# ì‚¬ì´ë“œë°” / ê²½ë¡œ
# ------------------------------
st.sidebar.header("ğŸ“ ë°ì´í„° ì†ŒìŠ¤ ì„¤ì •")

DEFAULT_SO = "data/survey_results_public.csv"
DEFAULT_AI = "data/Survey on Integrating Artificial Intelligence Tools within Agile Frameworks for Enhanced Software Development (Responses) - Sheet1.csv"

dataset = st.sidebar.radio(
    "ë¶„ì„ ëŒ€ìƒ ì„ íƒ",
    ["AI in Agile ì„¤ë¬¸", "Stack Overflow 2023"],
    index=0,
    key="dataset_radio"
)

st.sidebar.markdown("---")

# ============================================================
# AI in Agile ì„¤ë¬¸
# ============================================================
if dataset == "AI in Agile ì„¤ë¬¸":
    # --------------------------
    # íƒ€ì´í‹€ & ì„¤ëª… (tips ìŠ¤íƒ€ì¼)
    # --------------------------
    st.title("ğŸ’¡ AI in Agile ì„¤ë¬¸ ëŒ€ì‹œë³´ë“œ")
    st.write("")
    st.write("")
    st.caption("ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì—ì„œ AI ë„êµ¬ ì‚¬ìš© ê²½í—˜, ë„ì… ì˜í–¥, ê¸°ëŒ€ íš¨ê³¼Â·ìš°ë ¤, ì½”ë”© ì†ë„ í–¥ìƒì„ ì‹œê°ì ìœ¼ë¡œ íƒìƒ‰í•˜ëŠ” ëŒ€ì‹œë³´ë“œì…ë‹ˆë‹¤.")

    # --------------------------
    # ë°ì´í„° ì—…ë¡œë“œ
    # --------------------------
    up = st.sidebar.file_uploader("AI ì„¤ë¬¸ CSV ì—…ë¡œë“œ", type=["csv"], key="ai_csv")
    path = up if up is not None else DEFAULT_AI
    require_file(path, "AI ì„¤ë¬¸")
    ai = load_csv(path)

    mapper = {
        'Current Role: ': 'Role',
        'Familiarity with Agile Frameworks:': 'AgileFamiliarity',
        'Familiarity with Artificial Intelligence Tools(Like ChatGPT ):': 'AIFamiliarity',
        'Have you used artificial intelligence tools in software development projects before?': 'AIUsedBefore',
        'If yes, please specify the types of artificial intelligence tools you have used (check all that apply):': 'AIToolsUsed',
        'How do you perceive the potential benefits of integrating AI...e frameworks for software development? (Check all that apply):': 'Benefits',
        'What challenges do you foresee in integrating AI tools within agile frameworks? (Check all that apply):': 'Challenges',
        'On a scale of 1 to 5, how willing would you be to adopt AI tools within your agile development processes?': 'Willingness',
        'AI sped up coding': 'AISpeedUp',
    }
    ai = ai.rename(columns={k: v for k, v in mapper.items() if k in ai.columns})

    # ê²°ì¸¡ì¹˜ ì •ë¦¬
    for col in [
        "Role",
        "AgileFamiliarity",
        "AIFamiliarity",
        "AIUsedBefore",
        "AIToolsUsed",
        "Benefits",
        "Challenges",
        "AISpeedUp",
    ]:
        if col in ai.columns:
            ai[col] = ai[col].fillna("")

    if "Willingness" in ai.columns:
        ai["Willingness"] = pd.to_numeric(ai["Willingness"], errors="coerce")

    # --------------------------
    # ë°ì´í„°ì…‹ ì†Œê°œ (tips ìŠ¤íƒ€ì¼)
    # --------------------------
    st.subheader("ğŸ“‹ ì„¤ë¬¸ ë¬¸í•­ ì†Œê°œ")

    with st.expander("AI in Agile ì„¤ë¬¸ í•­ëª© ì„¤ëª…"):
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("- **Role**: í˜„ì¬ ì—­í•  (ê°œë°œì, í•™ìƒ, ë§¤ë‹ˆì € ë“±)")
            st.markdown("- **AgileFamiliarity**: ì• ìì¼ ë°©ë²•ë¡ ì— ëŒ€í•œ ì¹œìˆ™ë„")
            st.markdown("- **AIFamiliarity**: AI ë„êµ¬(ì˜ˆ: ChatGPT)ì— ëŒ€í•œ ì¹œìˆ™ë„")
            st.markdown("- **AIUsedBefore**: ê°œë°œ í”„ë¡œì íŠ¸ì—ì„œ AI ë„êµ¬ ì‚¬ìš© ì—¬ë¶€")
        with col2:
            st.markdown("- **AIToolsUsed**: ì‚¬ìš©í•´ë³¸ AI ë„êµ¬ ìœ í˜•(ë‹¤ì¤‘ ì„ íƒ)")
            st.markdown("- **Benefits**: AI ë„ì… ê¸°ëŒ€ íš¨ê³¼(ë‹¤ì¤‘ ì„ íƒ)")
            st.markdown("- **Challenges**: AI ë„ì… ì‹œ ìš°ë ¤Â·ì¥ì• ìš”ì¸(ë‹¤ì¤‘ ì„ íƒ)")
            st.markdown("- **Willingness (1~5)**: AI ë„ì… ì˜í–¥ ì ìˆ˜")
            st.markdown("- **AISpeedUp**: AIê°€ ì½”ë”© ì†ë„ë¥¼ ë†’ì—¬ì¤€ë‹¤ê³  ëŠê¼ˆëŠ”ì§€ ì—¬ë¶€")

        st.markdown("ğŸ’¡ í•´ë‹¹ í•­ëª©ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ **AI ë„ì… ì¤€ë¹„ë„**ì™€ **ê°œë°œ ë¬¸í™” ë³€í™”**ë¥¼ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # --------------------------
    # ì‚¬ì´ë“œë°”: ë°ì´í„° í•„í„°
    # --------------------------
    st.sidebar.subheader("ğŸ” ë°ì´í„° í•„í„°")

    roles = sorted(
        [r for r in ai.get("Role", pd.Series(dtype=str)).dropna().unique() if r]
    ) if "Role" in ai.columns else []
    fams = sorted(
        [r for r in ai.get("AIFamiliarity", pd.Series(dtype=str)).dropna().unique() if r]
    ) if "AIFamiliarity" in ai.columns else []

    sel_roles = st.sidebar.multiselect("ì—­í• (Role)", roles, default=[], key="roles_ms")
    sel_fams = st.sidebar.multiselect("AI ë„êµ¬ ì¹œìˆ™ë„", fams, default=[], key="fams_ms")

    min_will = None
    if "Willingness" in ai.columns:
        min_will = st.sidebar.slider(
            "ìµœì†Œ ë„ì… ì˜í–¥ ì ìˆ˜ (1~5)", 1, 5, 1, step=1, key="min_will_ai"
        )

    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ“Š ì‹œê°í™” ì˜µì…˜")
    show_ai_used = st.sidebar.checkbox("AI ì‚¬ìš© ê²½í—˜ ë¶„í¬", True, key="show_ai_used")
    show_ai_tools = st.sidebar.checkbox("ì‚¬ìš©í•œ AI ë„êµ¬ ìœ í˜•", True, key="show_ai_tools")
    show_benefits = st.sidebar.checkbox("ê¸°ëŒ€ íš¨ê³¼ ë¶„í¬", True, key="show_benefits")
    show_challenges = st.sidebar.checkbox("ìš°ë ¤Â·ì¥ì• ìš”ì¸ ë¶„í¬", True, key="show_challenges")
    show_willingness = st.sidebar.checkbox("ë„ì… ì˜í–¥ ë¶„í¬", True, key="show_will")
    show_speedup = st.sidebar.checkbox("ì½”ë”© ì†ë„ í–¥ìƒ ì—¬ë¶€", True, key="show_speed")
    show_speed_vs_will = st.sidebar.checkbox("ë„ì… ì˜í–¥ vs ì†ë„ í–¥ìƒ", True, key="show_speed_vs_will")

    # --------------------------
    # í•„í„° ì ìš©
    # --------------------------
    df_f = ai.copy()
    if sel_roles and "Role" in df_f.columns:
        df_f = df_f[df_f["Role"].isin(sel_roles)]
    if sel_fams and "AIFamiliarity" in df_f.columns:
        df_f = df_f[df_f["AIFamiliarity"].isin(sel_fams)]
    if min_will is not None and "Willingness" in df_f.columns:
        df_f = df_f[df_f["Willingness"].fillna(0) >= min_will]

    # --------------------------
    # í•„í„°ë§ëœ ë°ì´í„° (tips ìŠ¤íƒ€ì¼)
    # --------------------------
    st.write("")
    with st.expander(f"ğŸ“Š í•„í„°ë§ëœ ë°ì´í„° (ì´ {df_f.shape[0]}ê°œ í–‰)"):
        st.dataframe(df_f)

    st.write("")
    st.write("")

    # --------------------------
    # ìš”ì•½ í†µê³„ (Metrics, tips ìŠ¤íƒ€ì¼)
    # --------------------------
    st.subheader("ğŸ“ˆ ìš”ì•½ í†µê³„")

    k1, k2, k3, k4 = st.columns(4)

    with k1:
        if "AIUsedBefore" in df_f.columns and len(df_f) > 0:
            used_rate = (
                df_f["AIUsedBefore"]
                .astype(str)
                .str.lower()
                .isin(["yes", "y", "true", "1"])
                .mean()
                * 100
            )
            st.metric("AI ì‚¬ìš© ê²½í—˜ë¥ (%)", f"{used_rate:.1f}")
        else:
            st.metric("AI ì‚¬ìš© ê²½í—˜ë¥ (%)", "N/A")

    with k2:
        if "Willingness" in df_f.columns and df_f["Willingness"].notna().any():
            st.metric("í‰ê·  ë„ì… ì˜í–¥(1~5)", f"{df_f['Willingness'].mean():.2f}")
        else:
            st.metric("í‰ê·  ë„ì… ì˜í–¥(1~5)", "N/A")

    with k3:
        if "Willingness" in df_f.columns and df_f["Willingness"].notna().any():
            st.metric("ë„ì… ì˜í–¥ ì¤‘ì•™ê°’", f"{df_f['Willingness'].median():.2f}")
        else:
            st.metric("ë„ì… ì˜í–¥ ì¤‘ì•™ê°’", "N/A")

    with k4:
        if "AISpeedUp" in df_f.columns and len(df_f) > 0:
            speed_rate = (
                df_f["AISpeedUp"]
                .astype(str)
                .str.lower()
                .isin(["yes", "y", "true", "1"])
                .mean()
                * 100
            )
            st.metric("ì½”ë”© ì†ë„ í–¥ìƒ ì²´ê°ë¥ (%)", f"{speed_rate:.1f}")
        else:
            st.metric("ì½”ë”© ì†ë„ í–¥ìƒ ì²´ê°ë¥ (%)", "N/A")

    st.write("")
    st.write("")

    # --------------------------
    # ì‹œê°í™” (tips êµ¬ì¡° ë§ì¶¤)
    # --------------------------
    st.subheader("ğŸ“‰ ì‹œê°í™”")

    # 1) AI ì‚¬ìš© ê²½í—˜
    if show_ai_used:
        st.markdown("#### 1) AI ì‚¬ìš© ê²½í—˜ ë¶„í¬")
        if "AIUsedBefore" in df_f.columns:
            vc = value_counts_pct(df_f["AIUsedBefore"])
            d = prep_for_chart(vc, "AIUsedBefore")
            if not d.empty:
                base = alt.Chart(d).properties(height=200)
                bars = base.mark_bar().encode(
                    y=alt.Y("AIUsedBefore:N", sort="-x", title="ê²½í—˜ ì—¬ë¶€"),
                    x=alt.X("count:Q", title="ì‘ë‹µ ìˆ˜"),
                    tooltip=["AIUsedBefore", "count", "percent"],
                )
                texts = base.mark_text(align="left", baseline="middle", dx=4).encode(
                    y=alt.Y("AIUsedBefore:N", sort="-x"),
                    x=alt.X("count:Q"),
                    text="count:Q",
                )
                st.altair_chart(bars + texts, use_container_width=True)
            st.dataframe(
                d.rename(
                    columns={"AIUsedBefore": "ê²½í—˜ ì—¬ë¶€", "count": "ì‘ë‹µ ìˆ˜", "percent": "ë¹„ìœ¨(%)"}
                )
            )

    # 2) ì‚¬ìš©í•œ AI ë„êµ¬ ìœ í˜•
    if show_ai_tools:
        st.markdown("#### 2) ì‚¬ìš©í•œ AI ë„êµ¬ ìœ í˜•")
        if "AIToolsUsed" in df_f.columns:
            tools = explode_multiselect(df_f, "AIToolsUsed")
            if len(tools) > 0:
                t = tools["AIToolsUsed"].map(TOOLS_MAP).fillna(tools["AIToolsUsed"])
                vc2 = value_counts_pct(t)
                d2 = prep_for_chart(vc2, "Tool_ko")
                d2["Tool_ko_wrapped"] = d2["Tool_ko"].apply(lambda s: wrap_label(s, 16))

                if not d2.empty:
                    base2 = alt.Chart(d2).properties(height=max(220, 28 * len(d2)))
                    bars2 = base2.mark_bar().encode(
                        y=alt.Y("Tool_ko_wrapped:N", sort="-x", title="ë„êµ¬"),
                        x=alt.X("count:Q", title="ì‘ë‹µ ìˆ˜"),
                        tooltip=["Tool_ko", "count", "percent"],
                    )
                    texts2 = base2.mark_text(align="left", baseline="middle", dx=4).encode(
                        y=alt.Y("Tool_ko_wrapped:N", sort="-x"),
                        x=alt.X("count:Q"),
                        text="count:Q",
                    )
                    st.altair_chart(bars2 + texts2, use_container_width=True)

                tbl2 = d2[["Tool_ko", "count", "percent"]].rename(
                    columns={"Tool_ko": "ë„êµ¬", "count": "ì‘ë‹µ ìˆ˜", "percent": "ë¹„ìœ¨(%)"}
                )
                st.dataframe(safe_sort(tbl2, "ì‘ë‹µ ìˆ˜", ascending=False))

    # 3) ê¸°ëŒ€ íš¨ê³¼
    if show_benefits:
        st.markdown("#### 3) ê¸°ëŒ€ íš¨ê³¼(Benefits)")
        if "Benefits" in df_f.columns:
            ben = explode_multiselect(df_f, "Benefits")
            if len(ben) > 0:
                ben["Benefits"] = ben["Benefits"].astype(str).str.strip()
                ben = ben[~ben["Benefits"].isin(EXCLUDE_TOKENS)]
                ben_ko = ben["Benefits"].map(BENEFITS_MAP).fillna(ben["Benefits"])

                vc3 = value_counts_pct(ben_ko)
                d3 = prep_for_chart(vc3, "Benefit_ko")
                d3["Benefit_ko_wrapped"] = d3["Benefit_ko"].apply(
                    lambda s: wrap_label(s, 16)
                )

                if not d3.empty:
                    base3 = alt.Chart(d3).properties(height=max(220, 28 * len(d3)))
                    bars3 = base3.mark_bar().encode(
                        y=alt.Y("Benefit_ko_wrapped:N", sort="-x", title="ê¸°ëŒ€ íš¨ê³¼"),
                        x=alt.X("count:Q", title="ì‘ë‹µ ìˆ˜"),
                        tooltip=["Benefit_ko", "count", "percent"],
                    )
                    texts3 = base3.mark_text(align="left", baseline="middle", dx=4).encode(
                        y=alt.Y("Benefit_ko_wrapped:N", sort="-x"),
                        x=alt.X("count:Q"),
                        text="count:Q",
                    )
                    st.altair_chart(bars3 + texts3, use_container_width=True)

                st.dataframe(
                    d3[["Benefit_ko", "count", "percent"]].rename(
                        columns={
                            "Benefit_ko": "ê¸°ëŒ€ íš¨ê³¼(í•œê¸€)",
                            "count": "ì‘ë‹µ ìˆ˜",
                            "percent": "ë¹„ìœ¨(%)",
                        }
                    )
                )

    # 4) ìš°ë ¤/ì¥ì• ìš”ì¸
    if show_challenges:
        st.markdown("#### 4) ìš°ë ¤/ì¥ì• ìš”ì¸(Challenges)")
        if "Challenges" in df_f.columns:
            ch = explode_multiselect(df_f, "Challenges")
            if len(ch) > 0:
                ch["Challenges"] = ch["Challenges"].astype(str).str.strip()
                ch = ch[~ch["Challenges"].isin(EXCLUDE_TOKENS)]
                ch_ko = ch["Challenges"].map(CHALLENGE_MAP).fillna(ch["Challenges"])

                vc4 = value_counts_pct(ch_ko)
                d4 = prep_for_chart(vc4, "Challenge_ko")
                d4["Challenge_ko_wrapped"] = d4["Challenge_ko"].apply(
                    lambda s: wrap_label(s, 16)
                )

                if not d4.empty:
                    base4 = alt.Chart(d4).properties(height=max(220, 28 * len(d4)))
                    bars4 = base4.mark_bar().encode(
                        y=alt.Y("Challenge_ko_wrapped:N", sort="-x", title="ì¥ì• ìš”ì¸"),
                        x=alt.X("count:Q", title="ì‘ë‹µ ìˆ˜"),
                        tooltip=["Challenge_ko", "count", "percent"],
                    )
                    texts4 = base4.mark_text(align="left", baseline="middle", dx=4).encode(
                        y=alt.Y("Challenge_ko_wrapped:N", sort="-x"),
                        x=alt.X("count:Q"),
                        text="count:Q",
                    )
                    st.altair_chart(bars4 + texts4, use_container_width=True)

                tbl4 = d4[["Challenge_ko", "count", "percent"]].rename(
                    columns={"Challenge_ko": "ì¥ì• ìš”ì¸(í•œê¸€)", "count": "ì‘ë‹µ ìˆ˜", "percent": "ë¹„ìœ¨(%)"}
                )
                st.dataframe(safe_sort(tbl4, "ì‘ë‹µ ìˆ˜", ascending=False))

    # 5) ë„ì… ì˜í–¥ ë¶„í¬
    if show_willingness:
        st.markdown("#### 5) ë„ì… ì˜í–¥ ë¶„í¬ (1=ë‚®ìŒ, 5=ë§¤ìš° ë†’ìŒ)")
        if "Willingness" in df_f.columns and df_f["Willingness"].notna().any():
            vc5 = value_counts_pct(df_f["Willingness"].dropna())
            d5 = prep_for_chart(vc5, "Score")

            if not d5.empty and "Score" in d5.columns:
                chart5 = alt.Chart(d5).mark_bar().encode(
                    x=alt.X("Score:O", title="ë„ì… ì˜í–¥ ì ìˆ˜"),
                    y=alt.Y("count:Q", title="ì‘ë‹µ ìˆ˜"),
                    tooltip=["Score", "count", "percent"],
                )
                st.altair_chart(chart5, use_container_width=True)

                tbl5 = d5.rename(
                    columns={"Score": "ì ìˆ˜", "count": "ì‘ë‹µ ìˆ˜", "percent": "ë¹„ìœ¨(%)"}
                )
                st.dataframe(safe_sort(tbl5, "ì ìˆ˜"))
            else:
                st.info("ìœ íš¨í•œ ë„ì… ì˜í–¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ë„ì… ì˜í–¥(Willingness) ì»¬ëŸ¼ì´ ì—†ê±°ë‚˜ ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")

    # 6) AI ì‚¬ìš© í›„ ì½”ë”© ì†ë„ í–¥ìƒ ì—¬ë¶€
    if show_speedup:
        st.markdown("#### 6) AI ì‚¬ìš© í›„ ì½”ë”© ì†ë„ í–¥ìƒ ì—¬ë¶€")
        if "AISpeedUp" in df_f.columns:
            vc6 = value_counts_pct(df_f["AISpeedUp"])
            d6 = prep_for_chart(vc6, "AISpeedUp")

            if not d6.empty:
                base6 = alt.Chart(d6).properties(height=200)
                bars6 = base6.mark_bar().encode(
                    y=alt.Y("AISpeedUp:N", sort="-x", title="ì½”ë”© ì†ë„ í–¥ìƒ ì—¬ë¶€"),
                    x=alt.X("count:Q", title="ì‘ë‹µ ìˆ˜"),
                    tooltip=["AISpeedUp", "count", "percent"],
                )
                texts6 = base6.mark_text(align="left", baseline="middle", dx=4).encode(
                    y=alt.Y("AISpeedUp:N", sort="-x"),
                    x=alt.X("count:Q"),
                    text="count:Q",
                )
                st.altair_chart(bars6 + texts6, use_container_width=True)

            st.dataframe(
                d6.rename(
                    columns={"AISpeedUp": "ì½”ë”© ì†ë„ í–¥ìƒ ì—¬ë¶€", "count": "ì‘ë‹µ ìˆ˜", "percent": "ë¹„ìœ¨(%)"}
                )
            )
        else:
            st.info("'AI sped up coding' ì»¬ëŸ¼(AISpeedUp)ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")

    # 7) ë„ì… ì˜í–¥ vs ì½”ë”© ì†ë„ í–¥ìƒ
    if show_speed_vs_will:
        st.markdown("#### 7) ë„ì… ì˜í–¥ vs ì½”ë”© ì†ë„ í–¥ìƒ ê´€ê³„")
        if "Willingness" in df_f.columns and "AISpeedUp" in df_f.columns:
            tmp = df_f.copy()
            tmp["AISpeedUpLabel"] = (
                tmp["AISpeedUp"]
                .astype(str)
                .str.lower()
                .map(
                    {
                        "yes": "í–¥ìƒ ëŠê¼ˆìŒ",
                        "y": "í–¥ìƒ ëŠê¼ˆìŒ",
                        "true": "í–¥ìƒ ëŠê¼ˆìŒ",
                        "1": "í–¥ìƒ ëŠê¼ˆìŒ",
                    }
                )
            )
            tmp["AISpeedUpLabel"] = tmp["AISpeedUpLabel"].fillna("í–¥ìƒ ëª» ëŠë‚Œ/ë¯¸ì‘ë‹µ")
            tmp = tmp[tmp["Willingness"].notna()]
            if not tmp.empty:
                grp = (
                    tmp.groupby("AISpeedUpLabel")["Willingness"]
                    .agg(["mean", "count"])
                    .reset_index()
                )
                grp["mean"] = grp["mean"].round(2)
                chart7 = alt.Chart(grp).mark_bar().encode(
                    x=alt.X("AISpeedUpLabel:N", title="ì½”ë”© ì†ë„ í–¥ìƒ ì¸ì‹"),
                    y=alt.Y("mean:Q", title="í‰ê·  ë„ì… ì˜í–¥ ì ìˆ˜"),
                    tooltip=["AISpeedUpLabel", "mean", "count"],
                )
                st.altair_chart(chart7, use_container_width=True)
                st.dataframe(
                    grp.rename(
                        columns={
                            "AISpeedUpLabel": "ì½”ë”© ì†ë„ í–¥ìƒ ì¸ì‹",
                            "mean": "í‰ê·  ë„ì… ì˜í–¥",
                            "count": "ì‘ë‹µ ìˆ˜",
                        }
                    )
                )
            else:
                st.info("ë„ì… ì˜í–¥ê³¼ ì†ë„ í–¥ìƒ ì‘ë‹µì´ ëª¨ë‘ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("Willingness ë˜ëŠ” AISpeedUp ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    # --------------------------
    # CSV ë‹¤ìš´ë¡œë“œ
    # --------------------------
    st.download_button(
        "ğŸ”½ í˜„ì¬ í•„í„° ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
        data=df_f.to_csv(index=False).encode("utf-8-sig"),
        file_name="ai_agile_filtered.csv",
        mime="text/csv",
    )

# ============================================================
# Stack Overflow 2023
# ============================================================
else:
    # --------------------------
    # íƒ€ì´í‹€ & ì„¤ëª…
    # --------------------------
    st.title("ğŸ’¡ Stack Overflow 2023 ê°œë°œì ì„¤ë¬¸ ëŒ€ì‹œë³´ë“œ")
    st.write("")
    st.write("")
    st.caption("ê°œë°œì ì§ë¬´, ì‚¬ìš© ì–¸ì–´, ê²½ë ¥, êµ­ê°€, ì¡°ì§ ê·œëª¨ ë¶„í¬ë¥¼ íƒìƒ‰í•˜ëŠ” ëŒ€ì‹œë³´ë“œì…ë‹ˆë‹¤.")

    # ë°ì´í„° ì—…ë¡œë“œ
    up = st.sidebar.file_uploader("SO 2023 CSV ì—…ë¡œë“œ", type=["csv"], key="so_csv")
    path = up if up is not None else DEFAULT_SO
    require_file(path, "SO 2023 ë°ì´í„°")
    so = load_csv(path)

    # ë°ì´í„°ì…‹ ì†Œê°œ
    st.subheader("ğŸ“‹ ì„¤ë¬¸ ë¬¸í•­ ì†Œê°œ")
    with st.expander("Stack Overflow 2023 ì£¼ìš” ì»¬ëŸ¼ ì„¤ëª…"):
        c1, c2 = st.columns(2)
        with c1:
            st.markdown("- **DevType**: ê°œë°œì ì§ë¬´ ìœ í˜•(ë°±ì—”ë“œ, í”„ë¡ íŠ¸ì—”ë“œ, ë°ì´í„° ë“±)")
            st.markdown("- **LanguageHaveWorkedWith**: ì‚¬ìš©í•´ë³¸ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ëª©ë¡")
            st.markdown("- **YearsCodePro**: í”„ë¡œ ê°œë°œ ê²½ë ¥(ë…„)")
        with c2:
            st.markdown("- **Country**: ê±°ì£¼ êµ­ê°€")
            st.markdown("- **OrgSize**: í˜„ì¬ ì¡°ì§ ê·œëª¨")
            st.markdown("- ê¸°íƒ€ ì»¬ëŸ¼: ê·¼ë¬´ í˜•íƒœ, í•™ë ¥, ì‚¬ìš© ë„êµ¬ ë“±")

        st.markdown("ğŸ’¡ ì§ë¬´ì™€ ì–¸ì–´, ê²½ë ¥, ì¡°ì§ ê·œëª¨ë¥¼ í•¨ê»˜ ë³´ë©´ **ê°œë°œ ìƒíƒœê³„ì˜ êµ¬ì¡°**ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # Sidebar í•„í„°
    st.sidebar.subheader("ğŸ” ë°ì´í„° í•„í„°")

    countries = sorted(
        [c for c in so.get("Country", pd.Series(dtype=str)).dropna().unique() if c]
    ) if "Country" in so.columns else []
    sel_countries = st.sidebar.multiselect(
        "êµ­ê°€", countries, default=[], key="country_ms"
    )

    orgs = sorted(
        [o for o in so.get("OrgSize", pd.Series(dtype=str)).dropna().unique() if o]
    ) if "OrgSize" in so.columns else []
    sel_orgs = st.sidebar.multiselect(
        "ì¡°ì§ ê·œëª¨", orgs, default=[], key="org_ms"
    )

    min_years = None
    if "YearsCodePro" in so.columns:
        min_years = st.sidebar.slider(
            "ìµœì†Œ ê²½ë ¥(ë…„)", 0, 50, 0, step=1, key="min_years_so"
        )

    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ“Š ì‹œê°í™” ì˜µì…˜")
    show_devtype = st.sidebar.checkbox("ì§ë¬´(DevType) ë¶„í¬", True, key="show_devtype")
    show_lang = st.sidebar.checkbox("ì‚¬ìš© ì–¸ì–´ ë¶„í¬", True, key="show_lang")
    show_years = st.sidebar.checkbox("ê²½ë ¥(YearsCodePro) ë¶„í¬", True, key="show_years")
    show_country = st.sidebar.checkbox("êµ­ê°€ ë¶„í¬(Country)", True, key="show_country")
    show_orgsize = st.sidebar.checkbox("ì¡°ì§ ê·œëª¨ ë¶„í¬(OrgSize)", True, key="show_orgsize")

    # í•„í„° ì ìš©
    so_f = so.copy()
    if sel_countries and "Country" in so_f.columns:
        so_f = so_f[so_f["Country"].isin(sel_countries)]
    if sel_orgs and "OrgSize" in so_f.columns:
        so_f = so_f[so_f["OrgSize"].isin(sel_orgs)]
    if min_years is not None and "YearsCodePro" in so_f.columns:
        y = so_f["YearsCodePro"].replace(
            {"Less than 1 year": "0", "More than 50 years": "51"}
        )
        y_num = pd.to_numeric(y, errors="coerce")
        so_f = so_f[y_num >= min_years]

    # í•„í„°ë§ëœ ë°ì´í„°
    st.write("")
    with st.expander(f"ğŸ“Š í•„í„°ë§ëœ ë°ì´í„° (ì´ {so_f.shape[0]}ê°œ í–‰)"):
        st.dataframe(so_f.head(200))

    st.write("")
    st.write("")

    # ìš”ì•½ í†µê³„ (ê°„ë‹¨ KPI)
    st.subheader("ğŸ“ˆ ìš”ì•½ í†µê³„")
    c1, c2, c3, c4 = st.columns(4)

    with c1:
        st.metric("ì‘ë‹µì ìˆ˜", f"{so_f.shape[0]}")
    with c2:
        if "Country" in so_f.columns:
            st.metric("êµ­ê°€ ìˆ˜", f"{so_f['Country'].nunique()}")
        else:
            st.metric("êµ­ê°€ ìˆ˜", "N/A")
    with c3:
        if "LanguageHaveWorkedWith" in so_f.columns:
            lang_tmp = so_f["LanguageHaveWorkedWith"].fillna("").str.split(";").explode().str.strip()
            lang_tmp = lang_tmp[~lang_tmp.isin(EXCLUDE_TOKENS)]
            st.metric("ì‚¬ìš© ì–¸ì–´ ìˆ˜", f"{lang_tmp.nunique()}")
        else:
            st.metric("ì‚¬ìš© ì–¸ì–´ ìˆ˜", "N/A")
    with c4:
        if "YearsCodePro" in so_f.columns:
            y = so_f["YearsCodePro"].replace(
                {"Less than 1 year": "0", "More than 50 years": "51"}
            )
            y_num = pd.to_numeric(y, errors="coerce")
            if y_num.notna().any():
                st.metric("í‰ê·  ê²½ë ¥(ë…„)", f"{y_num.mean():.1f}")
            else:
                st.metric("í‰ê·  ê²½ë ¥(ë…„)", "N/A")
        else:
            st.metric("í‰ê·  ê²½ë ¥(ë…„)", "N/A")

    st.write("")
    st.write("")

    # ì‹œê°í™” ì˜ì—­
    st.subheader("ğŸ“‰ ì‹œê°í™”")

    # 1) DevType
    if show_devtype:
        st.markdown("#### 1) ì§ë¬´(DevType) ë¶„í¬")
        if "DevType" in so_f.columns:
            dev = so_f["DevType"].fillna("").str.split(";").explode().str.strip()
            dev = dev[~dev.isin(EXCLUDE_TOKENS)]
            if len(dev) > 0:
                dev_ko = dev.map(DEVTYPE_MAP).fillna(dev)
                vc = value_counts_pct(dev_ko)
                d = prep_for_chart(vc, "DevType_ko")
                d["DevType_ko_wrapped"] = d["DevType_ko"].apply(lambda s: wrap_label(s, 16))

                if not d.empty:
                    base = alt.Chart(d).properties(height=max(220, 28 * len(d)))
                    bars = base.mark_bar().encode(
                        y=alt.Y("DevType_ko_wrapped:N", sort="-x", title="ì§ë¬´"),
                        x=alt.X("count:Q", title="ì‘ë‹µ ìˆ˜"),
                        tooltip=["DevType_ko", "count", "percent"],
                    )
                    texts = base.mark_text(align="left", baseline="middle", dx=4).encode(
                        y=alt.Y("DevType_ko_wrapped:N", sort="-x"),
                        x=alt.X("count:Q"),
                        text="count:Q",
                    )
                    st.altair_chart(bars + texts, use_container_width=True)

                tbl_dev = d.rename(
                    columns={"DevType_ko": "ì§ë¬´", "count": "ì‘ë‹µ ìˆ˜", "percent": "ë¹„ìœ¨(%)"}
                )
                st.dataframe(safe_sort(tbl_dev, "ì‘ë‹µ ìˆ˜", ascending=False))

    # 2) LanguageHaveWorkedWith
    if show_lang:
        st.markdown("#### 2) ì‚¬ìš© ì–¸ì–´(LanguageHaveWorkedWith)")
        if "LanguageHaveWorkedWith" in so_f.columns:
            lang = so_f["LanguageHaveWorkedWith"].fillna("").str.split(";").explode().str.strip()
            lang = lang[~lang.isin(EXCLUDE_TOKENS)]
            if len(lang) > 0:
                vc2 = value_counts_pct(lang)
                d2 = prep_for_chart(vc2, "Language")
                d2["Language_wrapped"] = d2["Language"].apply(lambda s: wrap_label(s, 16))

                if not d2.empty:
                    base2 = alt.Chart(d2).properties(height=max(220, 28 * len(d2)))
                    bars2 = base2.mark_bar().encode(
                        y=alt.Y("Language_wrapped:N", sort="-x", title="ì–¸ì–´"),
                        x=alt.X("count:Q", title="ì‘ë‹µ ìˆ˜"),
                        tooltip=["Language", "count", "percent"],
                    )
                    texts2 = base2.mark_text(align="left", baseline="middle", dx=4).encode(
                        y=alt.Y("Language_wrapped:N", sort="-x"),
                        x=alt.X("count:Q"),
                        text="count:Q",
                    )
                    st.altair_chart(bars2 + texts2, use_container_width=True)

                st.dataframe(
                    d2.rename(
                        columns={"Language": "ì–¸ì–´", "count": "ì‘ë‹µ ìˆ˜", "percent": "ë¹„ìœ¨(%)"}
                    ).pipe(lambda x: safe_sort(x, "ì‘ë‹µ ìˆ˜", ascending=False))
                )

    # 3) YearsCodePro
    if show_years:
        st.markdown("#### 3) ê²½ë ¥(YearsCodePro) ë¶„í¬")
        if "YearsCodePro" in so_f.columns:
            y = so_f["YearsCodePro"].replace(
                {"Less than 1 year": "0", "More than 50 years": "51"}
            )
            y_num = pd.to_numeric(y, errors="coerce").dropna()
            vc3 = value_counts_pct(y_num)
            d3 = prep_for_chart(vc3, "Years")
            if not d3.empty:
                chart3 = alt.Chart(d3).mark_bar().encode(
                    x=alt.X("Years:Q", title="ê²½ë ¥(ë…„)"),
                    y=alt.Y("count:Q", title="ì‘ë‹µ ìˆ˜"),
                    tooltip=["Years", "count", "percent"],
                )
                st.altair_chart(chart3, use_container_width=True)
            st.dataframe(
                d3.rename(
                    columns={"Years": "ê²½ë ¥(ë…„)", "count": "ì‘ë‹µ ìˆ˜", "percent": "ë¹„ìœ¨(%)"}
                ).pipe(lambda x: safe_sort(x, "Years"))
            )

    # 4) êµ­ê°€ ë¶„í¬
    if show_country:
        st.markdown("#### 4) êµ­ê°€ ë¶„í¬(Country)")
        if "Country" in so_f.columns:
            vc_c = value_counts_pct(so_f["Country"])
            dc = prep_for_chart(vc_c, "Country")
            dc["Country_wrapped"] = dc["Country"].apply(lambda s: wrap_label(s, 18))
            if not dc.empty:
                base_c = alt.Chart(dc).properties(height=max(220, 26 * len(dc)))
                bars_c = base_c.mark_bar().encode(
                    y=alt.Y("Country_wrapped:N", sort="-x", title="êµ­ê°€"),
                    x=alt.X("count:Q", title="ì‘ë‹µ ìˆ˜"),
                    tooltip=["Country", "count", "percent"],
                )
                texts_c = base_c.mark_text(align="left", baseline="middle", dx=4).encode(
                    y=alt.Y("Country_wrapped:N", sort="-x"),
                    x=alt.X("count:Q"),
                    text="count:Q",
                )
                st.altair_chart(bars_c + texts_c, use_container_width=True)
            st.dataframe(
                dc.rename(
                    columns={"Country": "êµ­ê°€", "count": "ì‘ë‹µ ìˆ˜", "percent": "ë¹„ìœ¨(%)"}
                ).pipe(lambda x: safe_sort(x, "ì‘ë‹µ ìˆ˜", ascending=False))
            )

    # 5) ì¡°ì§ ê·œëª¨ ë¶„í¬
    if show_orgsize:
        st.markdown("#### 5) ì¡°ì§ ê·œëª¨ ë¶„í¬(OrgSize)")
        if "OrgSize" in so_f.columns:
            vc_o = value_counts_pct(so_f["OrgSize"])
            do = prep_for_chart(vc_o, "OrgSize")
            do["OrgSize_wrapped"] = do["OrgSize"].apply(lambda s: wrap_label(s, 24))
            if not do.empty:
                base_o = alt.Chart(do).properties(height=max(220, 26 * len(do)))
                bars_o = base_o.mark_bar().encode(
                    y=alt.Y("OrgSize_wrapped:N", sort="-x", title="ì¡°ì§ ê·œëª¨"),
                    x=alt.X("count:Q", title="ì‘ë‹µ ìˆ˜"),
                    tooltip=["OrgSize", "count", "percent"],
                )
                texts_o = base_o.mark_text(align="left", baseline="middle", dx=4).encode(
                    y=alt.Y("OrgSize_wrapped:N", sort="-x"),
                    x=alt.X("count:Q"),
                    text="count:Q",
                )
                st.altair_chart(bars_o + texts_o, use_container_width=True)
            st.dataframe(
                do.rename(
                    columns={"OrgSize": "ì¡°ì§ ê·œëª¨", "count": "ì‘ë‹µ ìˆ˜", "percent": "ë¹„ìœ¨(%)"}
                ).pipe(lambda x: safe_sort(x, "ì‘ë‹µ ìˆ˜", ascending=False))
            )

    # CSV ë‹¤ìš´ë¡œë“œ
    st.download_button(
        "ğŸ”½ í˜„ì¬ í•„í„° ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
        data=so_f.to_csv(index=False).encode("utf-8-sig"),
        file_name="so2023_filtered.csv",
        mime="text/csv",
    )
